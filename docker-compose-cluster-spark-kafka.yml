## VERSION 1.1.0 DOCKER-COMPOSE 
version: "3.8"
services:

    zookeeper:
        image: wurstmeister/zookeeper:3.4.6
        container_name: zookeeper
        ports:
          - 2181:2181
        networks:
          - kafkanet


    kafka1:
        image: wurstmeister/kafka:2.13-2.7.0
        container_name: kafka1
        depends_on:
            - zookeeper
        environment:
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_ADVERTISED_PORT: 9092
            KAFKA_ADVERTISED_HOST_NAME: kafka1
            KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://localhost:19092
            KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://0.0.0.0:19092
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
            KAFKA_CREATE_TOPICS: sales-topic:1:1,fraud-topic:1:1,insurance-raw:8:1
            KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=2080:/prometheus/kafka-0-8-2.yml
        command: [start-kafka.sh]
        expose:
            - "2080"
            - "9092"
        ports:
            - 9092:9092
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
            - ./kafka/prometheus:/prometheus
            - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
        networks:
            - kafkanet
            - sparknet
            - mongodbnet

    kafka2:
        image: wurstmeister/kafka:2.13-2.7.0
        container_name: kafka2
        depends_on:
            - zookeeper
        environment:
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_ADVERTISED_PORT: 9093
            KAFKA_ADVERTISED_HOST_NAME: kafka2
            KAFKA_ADVERTISED_LISTENERS: INSIDE://:9093,OUTSIDE://localhost:19093
            KAFKA_LISTENERS: INSIDE://:9093,OUTSIDE://0.0.0.0:19093
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
            KAFKA_CREATE_TOPICS: sales-topic:1:1,fraud-topic:1:1,insurance-raw:8:1
            KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=2080:/prometheus/kafka-0-8-2.yml
        command: [start-kafka.sh]
        expose:
            - "2080"
            - "9093"
        ports:
            - 9093:9092
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
            - ./kafka/prometheus:/prometheus
            - kafka_kafka2:/opt/kafka_2.12-2.2.0/logs
        networks:
            - kafkanet
            - sparknet
            - mongodbnet

    database:
        image: postgres:11
        container_name: postgres
        environment:
            POSTGRES_USER: ${POSTGRES_USER}
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
        ports:
            - 5432:5432
        volumes:
            - ./services/database/schema.sql:/docker-entrypoint-initdb.d/1-schema.sql
            - ./services/database/seed.sql:/docker-entrypoint-initdb.d/2-seed.sql
            - postgres:/var/lib/postgresql/data
        networks:
            - kafkanet
            - sparknet
            - supersetnet       


    producer:
       # build: ./services/producer
        image: mrussorb/cluster-kafka:producer-pg-v${KAFKA_PROD_VER}
       # image: staging-producer:latest 
        container_name: kafka-producer
        command: sh -c "dockerize -wait tcp://zookeeper:2181 -wait tcp://kafka1:19092 -wait tcp://database:5432 npm start"
        depends_on:
            - zookeeper
            - kafka1
            - database
        environment:
            PGHOST: database
            PGPORT: 5432
            PGUSER: ${POSTGRES_USER}
            PGDATABASE: ${POSTGRES_DATABASE}
            PGPASSWORD: ${POSTGRES_PASSWORD}
            PRODUCER_PORT: ${PRODUCER_PORT}
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        ports:
            - ${PRODUCER_PORT}:${PRODUCER_PORT}
        networks:
            - kafkanet


    consumer:
        image: mrussorb/cluster-kafka:consumer-pg-v${KAFKA_CONS_VER}
        # build: ./services/consumer
        container_name: kafka-consumer
        command: sh -c "dockerize -wait tcp://zookeeper:2181 -wait tcp://kafka1:19092 -wait tcp://database:5432 npm start"
        depends_on:
            - zookeeper
            - kafka1
            - database
        environment:
            PGHOST: database
            PGPORT: 5432
            PGUSER: ${POSTGRES_USER}
            PGDATABASE: ${POSTGRES_DATABASE}
            PGPASSWORD: ${POSTGRES_PASSWORD}
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        networks:
            - kafkanet
            - sparknet
     
    jupyterlab:
        image: mrussorb/cluster-jupyterlab:${JUPYTERLAB_TAG_VERSION}
        container_name: jupyterlab
        ports:
            - 8888:8888
            - 4040:4040
        volumes:
            - shared-workspace:/opt/workspace
            - ./workspace:/opt/workspace/TFM
        networks:
            - sparknet
            - kafkanet

    grafana:
        image: grafana/grafana:7.5.5
        container_name: grafana
        expose:
            - "3000"
        ports:
            - 3000:3000
        environment:
            - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
        volumes:
            - ./grafana/provisioning/:/etc/grafana/provisioning/
            - ./grafana/provisioning/datasources/datasource.js:/etc/extra-config/grafana
        networks:
            - kafkanet
            - mongodbnet

    prometheus:
        image: prom/prometheus:v2.8.1
        container_name: prometheus
        expose:
            - "9090"
        volumes:
            - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
        depends_on:
            - "zookeeper"
            - "kafka1"
            - "kafka2"
        networks:
            - kafkanet
                #ipv4_address: 172.25.0.15

    spark-master:
        image: mrussorb/cluster-spark-master:${SPARK_MASTER_TAG_VERSION}
        container_name: spark-master
        environment:
            - SPARK_MODE=master
        expose:
            - "7077"
            - "8080"
        ports:
            - 7077:7077
            - 8080:8080
        volumes:
            - shared-workspace:/opt/workspace
        networks: 
            - sparknet
            - kafkanet
                        
    spark-worker-1:
        image: mrussorb/cluster-spark-worker:${SPARK_WORKER_TAG_VERSION}
        container_name: spark-worker-1
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=512m
            - SPARK_WORKER_CORES=1
        ports:
            - 8081:8081
        volumes:
            - shared-workspace:/opt/workspace
        depends_on:
            - spark-master
        networks:
            - sparknet
            - kafkanet

    spark-worker-2:
        image: mrussorb/cluster-spark-worker:${SPARK_WORKER_TAG_VERSION}
        container_name: spark-worker-2
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=512m
            - SPARK_WORKER_CORES=1
        ports:
            - 8082:8081
        volumes:
            - shared-workspace:/opt/workspace
        depends_on:
            - spark-master
        networks: 
            - sparknet
            - kafkanet

    spark-worker-3:
        image: mrussorb/cluster-spark-worker:${SPARK_WORKER_TAG_VERSION}
        container_name: spark-worker-3
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=512m
            - SPARK_WORKER_CORES=1
        ports:
            - 8083:8081
        volumes:
            - shared-workspace:/opt/workspace
        depends_on:
            - spark-master
        networks: 
            - sparknet
            - kafkanet


    redis:
        image: redis
        container_name: redis
        restart: always
        volumes:
            - redis:/data
        networks:
            - supersetnet
    
    superset:
        image: amancevice/superset
        #image: superset:v0.38.0
        container_name: superset
        restart: always
        depends_on:
            - redis
            - database
        environment:
            MAPBOX_API_KEY: ./superset/superset_config.py/${MAPBOX_API_KEY}
            ADMIN_USERNAME: $SUPERSET_USERNAME
            ADMIN_FIRST_NAME: $SUPERSET_FIRSTNAME
            ADMIN_LAST_NAME: $SUPERSET_LASTNAME
            ADMIN_EMAIL: $SUPERSET_EMAIL
            ADMIN_PASSWORD: $SUPERSET_PASSWORD
        # command: [superset-init]
        ports:
            - 8088:8088
        expose:
            - "8088"
        volumes:
            - ./superset/superset_config.py:/etc/superset/superset_config.py
        networks:
            - supersetnet
            - kafkanet

    mlflow:                                             # create a MLFlow container
        build: './mlflow_docker'                        # construct the container along the Dockerfile in this folder
        #image: build_mlflow:latest
        container_name: mlflow_container
        ports:
            - "5000:5000"                               # expose port
        command: 'mlflow server --backend-store-uri ./mlflow --host 0.0.0.0 --port 5000'
        networks: 
            - sparknet




volumes:
    shared-workspace:
        name: "hadoop-distributed-file-system"
        driver: local
    redis:
    postgres:
    kafka_kafka1:
    kafka_kafka2:
    
    
networks:
    kafkanet:
        name : kafkanet
        driver: bridge
    sparknet:
        name: sparknet
        driver: bridge
    supersetnet:
        name: supersetnet
        driver: bridge
    mongodbnet:
        name: mongodbnet
        driver: bridge
        attachable: true