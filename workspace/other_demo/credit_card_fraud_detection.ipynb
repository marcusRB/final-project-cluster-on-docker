{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I have implemented credit card fraud detection model using Spark and LightGBMClassifier in Databricks runtime environment using dataset provided by Machine Learning Group at Universit√© libre de Bruxelles (ULB). The dataset with 300,000 rows consisting 31 variables related to European Credit Card holder's transactions out of which 28 are numeric variables derived by performing Principal Component Analysis on some unrevealed original parameters. The remaining three variables are Amount of transaction, time of transaction in seconds relative to first tranaction and Class of transaction indicating whether its genuine or fradulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ML\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mmlspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmlspark.lightgbm._LightGBMClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-df498625321c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmlspark/lightgbm/LightGBMClassifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbasestring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LightGBMClassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LightGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmlspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LightGBMClassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LightGBMClassificationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmlspark.lightgbm._LightGBMClassifier'"
     ]
    }
   ],
   "source": [
    "from mmlspark.lightgbm import LightGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmlspark import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mmlspark.lightgbm' from '/usr/local/lib/python3.7/dist-packages/mmlspark/lightgbm/__init__.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://14062e1d1894:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-notebook</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3d66be9a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"../../data/creditcard.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-1.158233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.072781</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>0.877737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>2.536347</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>1.548718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>1.378155</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>0.403034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>-0.407193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.462388</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.095921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.239599</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.592941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-0.270533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.363787</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>0.817739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>0.753074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.551600</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>-0.822843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>-0.617801</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.538196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.991390</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>1.345852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.119670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>1.468177</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>0.175121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.451449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.207971</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>-0.237033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.025791</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-0.038195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.403993</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>0.803487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>0.408542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>-0.018307</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>-0.009431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.798278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-0.137458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>0.066928</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.141267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.128539</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.206010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.502292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.219422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>149.620000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>69.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1           2           3          4\n",
       "Time      0.000000  0.000000    1.000000    1.000000   2.000000\n",
       "V1       -1.359807  1.191857   -1.358354   -0.966272  -1.158233\n",
       "V2       -0.072781  0.266151   -1.340163   -0.185226   0.877737\n",
       "V3        2.536347  0.166480    1.773209    1.792993   1.548718\n",
       "V4        1.378155  0.448154    0.379780   -0.863291   0.403034\n",
       "V5       -0.338321  0.060018   -0.503198   -0.010309  -0.407193\n",
       "V6        0.462388 -0.082361    1.800499    1.247203   0.095921\n",
       "V7        0.239599 -0.078803    0.791461    0.237609   0.592941\n",
       "V8        0.098698  0.085102    0.247676    0.377436  -0.270533\n",
       "V9        0.363787 -0.255425   -1.514654   -1.387024   0.817739\n",
       "V10       0.090794 -0.166974    0.207643   -0.054952   0.753074\n",
       "V11      -0.551600  1.612727    0.624501   -0.226487  -0.822843\n",
       "V12      -0.617801  1.065235    0.066084    0.178228   0.538196\n",
       "V13      -0.991390  0.489095    0.717293    0.507757   1.345852\n",
       "V14      -0.311169 -0.143772   -0.165946   -0.287924  -1.119670\n",
       "V15       1.468177  0.635558    2.345865   -0.631418   0.175121\n",
       "V16      -0.470401  0.463917   -2.890083   -1.059647  -0.451449\n",
       "V17       0.207971 -0.114805    1.109969   -0.684093  -0.237033\n",
       "V18       0.025791 -0.183361   -0.121359    1.965775  -0.038195\n",
       "V19       0.403993 -0.145783   -2.261857   -1.232622   0.803487\n",
       "V20       0.251412 -0.069083    0.524980   -0.208038   0.408542\n",
       "V21      -0.018307 -0.225775    0.247998   -0.108300  -0.009431\n",
       "V22       0.277838 -0.638672    0.771679    0.005274   0.798278\n",
       "V23      -0.110474  0.101288    0.909412   -0.190321  -0.137458\n",
       "V24       0.066928 -0.339846   -0.689281   -1.175575   0.141267\n",
       "V25       0.128539  0.167170   -0.327642    0.647376  -0.206010\n",
       "V26      -0.189115  0.125895   -0.139097   -0.221929   0.502292\n",
       "V27       0.133558 -0.008983   -0.055353    0.062723   0.219422\n",
       "V28      -0.021053  0.014724   -0.059752    0.061458   0.215153\n",
       "Amount  149.620000  2.690000  378.660000  123.500000  69.990000\n",
       "Class     0.000000  0.000000    0.000000    0.000000   0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time: double (nullable = true)\n",
      " |-- V1: double (nullable = true)\n",
      " |-- V2: double (nullable = true)\n",
      " |-- V3: double (nullable = true)\n",
      " |-- V4: double (nullable = true)\n",
      " |-- V5: double (nullable = true)\n",
      " |-- V6: double (nullable = true)\n",
      " |-- V7: double (nullable = true)\n",
      " |-- V8: double (nullable = true)\n",
      " |-- V9: double (nullable = true)\n",
      " |-- V10: double (nullable = true)\n",
      " |-- V11: double (nullable = true)\n",
      " |-- V12: double (nullable = true)\n",
      " |-- V13: double (nullable = true)\n",
      " |-- V14: double (nullable = true)\n",
      " |-- V15: double (nullable = true)\n",
      " |-- V16: double (nullable = true)\n",
      " |-- V17: double (nullable = true)\n",
      " |-- V18: double (nullable = true)\n",
      " |-- V19: double (nullable = true)\n",
      " |-- V20: double (nullable = true)\n",
      " |-- V21: double (nullable = true)\n",
      " |-- V22: double (nullable = true)\n",
      " |-- V23: double (nullable = true)\n",
      " |-- V24: double (nullable = true)\n",
      " |-- V25: double (nullable = true)\n",
      " |-- V26: double (nullable = true)\n",
      " |-- V27: double (nullable = true)\n",
      " |-- V28: double (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|Class| count|\n",
      "+-----+------+\n",
      "|    1|   492|\n",
      "|    0|284315|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above counts for each class value, the dataset is heavily imbalanced. One approach that we can use is to assign different weights to classes in our binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"V\" + str(i) for i in range(1,29)] + [\"Amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I derived below params while training LightGBM model for this dataset in Python enviornment using Tree of Parzen Estimators algorithm implemented in Hyperopt library. Using them right now to get started quickly with great performance on our test outcome. It's also possible to do model tuning inside Spark using ParamGridBuilder and CrossValidator, although it will take more time to explore the hyperparameter space without using Bayesian Optimization or Tree of Parzen's Estimator algorithm to quickly find optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/patelatharva/credit-card-transaction-fraud-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {   \n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'eval_metric': 'binary_error',\n",
    "    'feature_fraction': 0.944714847210862,\n",
    "    'lambda_l1': 1.0,\n",
    "    'lambda_l2': 45.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'loss_function': 'binary_error',\n",
    "    'max_bin': 60,\n",
    "    'max_depth': 58,\n",
    "    'metric': 'binary_error',\n",
    "    'num_iterations': 379,\n",
    "    'num_leaves': 850,\n",
    "    'objective': 'binary',\n",
    "    'random_state': 7,\n",
    "    'verbose': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LightGBMClassifier(learningRate=0.1,\n",
    "                  earlyStoppingRound=100,\n",
    "                  featuresCol='features',\n",
    "                  labelCol='Class',\n",
    "                  isUnbalance=True,\n",
    "                  baggingFraction=best_params[\"bagging_fraction\"],\n",
    "                  baggingFreq=1,\n",
    "                  featureFraction=best_params[\"feature_fraction\"],\n",
    "                  lambdaL1=best_params[\"lambda_l1\"],\n",
    "                  lambdaL2=best_params[\"lambda_l2\"],\n",
    "                  maxBin=best_params[\"max_bin\"],\n",
    "                  maxDepth=best_params[\"max_depth\"],\n",
    "                  numIterations=best_params[\"num_iterations\"],\n",
    "                  numLeaves=best_params[\"num_leaves\"],\n",
    "                  objective=\"binary\",\n",
    "                  baggingSeed=7\n",
    "                  )\n",
    "stages += [lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipelineModel.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.select('Class', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryEvaluator = BinaryClassificationEvaluator(labelCol=\"Class\")\n",
    "print (\"Test Area Under ROC: \" + str(binaryEvaluator.evaluate(preds, {binaryEvaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = preds[(preds.Class == 1) & (preds.prediction == 1)].count()\n",
    "tn = preds[(preds.Class == 0) & (preds.prediction == 0)].count()\n",
    "fp = preds[(preds.Class == 0) & (preds.prediction == 1)].count()\n",
    "fn = preds[(preds.Class == 1) & (preds.prediction == 0)].count()\n",
    "\n",
    "print (\"True Positives:\", tp)\n",
    "\n",
    "print (\"True Negatives:\", tn)\n",
    "\n",
    "print (\"False Positives:\", fp)\n",
    "\n",
    "print (\"False Negatives:\", fn)\n",
    "\n",
    "print (\"Total\", preds.count())\n",
    "\n",
    "r = float(tp)/(tp + fn)\n",
    "\n",
    "print (\"recall\", r)\n",
    "\n",
    "p = float(tp) / (tp + fp)\n",
    "\n",
    "print (\"precision\", p)\n",
    "\n",
    "f1 = 2 * p * r /(p + r)\n",
    "\n",
    "print (\"f1\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directions to improve on F1 score and AUC ROC:\n",
    "1. Implementing Synthentic Minority Oversampling in Spark here before using the imbalanced training data for fitting the model. Currently I have relied upon LightGBMClassifier's isUnbalance=True flag to take care of this imbalance.\n",
    "2. Exploring the hyperparameter space more deeply to find out optimal values. The hyperparameters values that I have used here were found by doing 200 evaluations of different combinations of Parameter values using Hyperopt library with TPE algorithm for exploring hyperparam space. Here is my notebook where I first found out best parameter values to be used in this project https://www.kaggle.com/patelatharva/credit-card-transaction-fraud-detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "credit card fraud detection",
  "notebookId": 1558268608003263
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
